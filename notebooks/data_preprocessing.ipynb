{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0929da9a",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "This notebook handles missing values and prepares the Wikipedia traffic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee304ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Download and extract data from Kaggle first, then use the path below:\n",
    "# Example file: 'train_1.csv' from the Kaggle competition\n",
    "df = pd.read_csv('train_1.csv')\n",
    "\n",
    "# Show structure\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns)\n",
    "\n",
    "# Melt wide to long format\n",
    "df_long = df.melt(id_vars=['Page'], var_name='Date', value_name='Views')\n",
    "\n",
    "# Convert to datetime and fill NAs\n",
    "df_long['Date'] = pd.to_datetime(df_long['Date'])\n",
    "df_long['Views'] = df_long['Views'].fillna(0)\n",
    "\n",
    "# Preview cleaned data\n",
    "print(df_long.head())\n",
    "\n",
    "# Save cleaned for later use\n",
    "df_long.to_csv('wiki_traffic_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
